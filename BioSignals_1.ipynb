{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9bcfc1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conda install -c conda-forge opencv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a45b7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzing, cleaning, exploring data\n",
    "import pandas as pd \n",
    "from pandas import DataFrame\n",
    "import re\n",
    "\n",
    "# Performing math operations on arrays and other structures.\n",
    "import numpy as np\n",
    "\n",
    "# Visualizing data\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import pywt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73d48e8",
   "metadata": {},
   "source": [
    "## Importing data and extracting to a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f68412",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "new_list2 = []\n",
    "\n",
    "columns = ['Timestamp', 'El1', 'El2', 'El3','El4', 'El5', 'El6','El7', 'El8']\n",
    "\n",
    "\n",
    "# Specify the folder path where the CSV files are located\n",
    "folder_path = \"first_try/\"\n",
    "\n",
    "# Get a list of all CSV files in the folder\n",
    "file_list = glob.glob(folder_path + \"*.csv\")\n",
    "\n",
    "# Create an empty list to store the data from each CSV file\n",
    "dataframes = []\n",
    "total_num_rows = 0  # Variable to store the total number of rows\n",
    "extracted_strings = []\n",
    "\n",
    "\n",
    "# Loop through each CSV file, read it into a DataFrame, and append it to the list\n",
    "for file in file_list:\n",
    "    df = pd.read_csv(file, names=columns)\n",
    "    num_rows = df.shape[0]\n",
    "    \n",
    "    file_name = file.split(\"/\")[-1]  # Extract the file name from the file path\n",
    "    extracted_string = re.search(r'-(.*?)-', file_name).group(1)  # Extract the desired string using regex\n",
    "        \n",
    "    extracted_strings.extend([extracted_string] * num_rows)\n",
    "    \n",
    "    \n",
    "    extracted_numbers = re.findall(r'\\d+', file)[0]\n",
    "\n",
    "    \n",
    "    new_list = [extracted_numbers] * num_rows\n",
    "    new_list2.append(new_list)\n",
    "    dataframes.append(df)\n",
    "    \n",
    "    total_num_rows += num_rows\n",
    "\n",
    "\n",
    "# Concatenate all DataFrames in the list into a single DataFrame\n",
    "data = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "new_list2 = [item for sublist in new_list2 for item in sublist]  # Flatten the nested list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676ee5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"P_ID\"] = new_list2\n",
    "data[\"Gesture\"] = extracted_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32994c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "data['encoded_column'] = le.fit_transform(data['Gesture'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec73a1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11bbfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Gesture.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acc6083",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Gesture.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f8c8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.encoded_column.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e39e604",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28e9125",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c732ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = data.hist(figsize=(16, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c553f2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take time and one column and convert it into a wavelet transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983f15fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_data = data['Timestamp'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e9c985",
   "metadata": {},
   "outputs": [],
   "source": [
    "electrode1_data = data['El1'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818a7e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a730bb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "electrode1_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33228e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelet = 'db4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4709956c",
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs = pywt.wavedec(electrode_data, wavelet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e74968",
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650c833d",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189135f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3448f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the wavelet coefficients\n",
    "levels = len(coeffs)\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for i in range(levels):\n",
    "    level = levels - i\n",
    "    plt.subplot(levels, 1, i+1)\n",
    "    plt.plot(coeffs[i])\n",
    "    plt.title(f'Level {level} Coefficients')\n",
    "    plt.xlabel('Sample')\n",
    "    plt.ylabel('Coefficient')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf8dcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs = pywt.wavedec(electrode1_data, 'db4', level=8)\n",
    "reconstructed_signal = pywt.waverec(coeffs, 'db4')\n",
    " \n",
    "fig, ax = plt.subplots(figsize=(8,4))\n",
    "ax.plot(electrode1_data[:1000], label='signal')\n",
    "ax.plot(reconstructed_signal[:1000], label='reconstructed signal', linestyle='--')\n",
    "ax.legend(loc='upper left')\n",
    "ax.set_title('de- and reconstruction using wavedec()')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb747b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = electrode1_data\n",
    "def lowpassfilter(signal, thresh = 0.63, wavelet=\"db4\"):\n",
    "    thresh = thresh*np.nanmax(signal)\n",
    "    coeff = pywt.wavedec(signal, wavelet, mode=\"per\" )\n",
    "    coeff[1:] = (pywt.threshold(i, value=thresh, mode=\"soft\" ) for i in coeff[1:])\n",
    "    reconstructed_signal = pywt.waverec(coeff, wavelet, mode=\"per\" )\n",
    "    return reconstructed_signal\n",
    " \n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "ax.plot(signal, color=\"b\", alpha=0.5, label='original signal')\n",
    "rec = lowpassfilter(signal, 0.4)\n",
    "ax.plot(rec, 'k', label='DWT smoothing}', linewidth=2)\n",
    "ax.legend()\n",
    "ax.set_title('Removing High Frequency Noise with DWT', fontsize=18)\n",
    "ax.set_ylabel('Signal Amplitude', fontsize=16)\n",
    "ax.set_xlabel('Sample No', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f68d52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951f190c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98559f3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pywt\n",
    "\n",
    "# Assuming you have your dataset loaded into a pandas DataFrame called 'data'\n",
    "# 'timestamps' represents the column with timestamps\n",
    "# 'electrode_columns' represents the list of columns containing electrode readings\n",
    "\n",
    "# Define the wavelet function\n",
    "wavelet = 'db4'  # Select a suitable wavelet, such as Daubechies 4\n",
    "\n",
    "# Create an empty list to store the wavelet coefficients\n",
    "wavelet_coefficients = []\n",
    "\n",
    "electrode_columns = ['El1', 'El2', 'El3','El4', 'El5', 'El6','El7', 'El8']\n",
    "\n",
    "signal = data['El1'].values  # Get the electrode readings as a numpy array\n",
    "coefficients = pywt.wavedec(signal, wavelet, level=5)  # Perform wavelet decomposition\n",
    "\n",
    "    # Append the coefficients to the list\n",
    "wavelet_coefficients.extend(coefficients)\n",
    "\n",
    "# Convert the list of coefficients to a numpy array\n",
    "wavelet_coefficients = np.array(wavelet_coefficients,dtype=object )\n",
    "\n",
    "\n",
    "wavelet_coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64179339",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Reshape the coefficients into a suitable format for CNN input\n",
    "# The dimensions depend on the number of electrodes and the number of levels in the wavelet decomposition\n",
    "num_electrodes = 1\n",
    "num_levels = 5\n",
    "num_samples = len(data)  # Assuming each row represents a sample\n",
    "num_coeffs = wavelet_coefficients.shape[0]\n",
    "\n",
    "#reshaped_coefficients = wavelet_coefficients.reshape(num_samples, num_electrodes, num_levels, -1)\n",
    "\n",
    "# Now 'reshaped_coefficients' can be used as input for training a CNN model\n",
    "# You can proceed with further steps such as splitting the data, normalization, and training the model\n",
    "reshaped_coefficients = wavelet_coefficients.reshape(num_samples, -1, num_coeffs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3337b96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pywt\n",
    "\n",
    "# Assuming you have your dataset loaded into a pandas DataFrame called 'data'\n",
    "# 'timestamps' represents the column with timestamps\n",
    "# 'electrode_columns' represents the list of columns containing electrode readings\n",
    "\n",
    "# Define the wavelet function\n",
    "wavelet = 'db4'  # Select a suitable wavelet, such as Daubechies 4\n",
    "\n",
    "# Create an empty list to store the wavelet coefficients\n",
    "wavelet_coefficients = []\n",
    "\n",
    "electrode_columns = ['El1', 'El2', 'El3','El4', 'El5', 'El6','El7', 'El8']\n",
    "\n",
    "# Iterate through each electrode column\n",
    "for column in electrode_columns:\n",
    "    # Apply wavelet transform on each column\n",
    "    signal = data[column].values  # Get the electrode readings as a numpy array\n",
    "    coefficients = pywt.wavedec(signal, wavelet, level=5)  # Perform wavelet decomposition\n",
    "    print(len(coefficients))\n",
    "    # Append the coefficients to the list\n",
    "    wavelet_coefficients.append(coefficients)\n",
    "\n",
    "# Convert the list of coefficients to a numpy array\n",
    "wavelet_coefficients = np.array(wavelet_coefficients, dtype=object)\n",
    "\n",
    "# Get the dimensions of the coefficients array\n",
    "num_electrodes = len(electrode_columns)\n",
    "num_samples = len(data)  # Assuming each row represents a sample\n",
    "\n",
    "# Reshape the coefficients into a suitable format for CNN input\n",
    "reshaped_coefficients = wavelet_coefficients.reshape(wavelet_coefficients.shape[1], num_electrodes, -1)\n",
    "\n",
    "# Now 'reshaped_coefficients' can be used as input for training a CNN model\n",
    "# You can proceed with further steps such as splitting the data, normalization, and training the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9994c549",
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelet_coefficients.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1407aa00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5943cf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7211ae69",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"first_try/004a-open-0.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49876137",
   "metadata": {},
   "outputs": [],
   "source": [
    "del data[data.columns[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913ac878",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ac1a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b51a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4fdbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pywt\n",
    "import cv2\n",
    "\n",
    "# Load your data\n",
    "# Assuming you have a 2D array with dimensions (num_samples, num_channels)\n",
    "\n",
    "# Define the wavelet and desired number of scales\n",
    "wavelet = 'morl'  # Choose the wavelet function\n",
    "num_scales = 6  # Number of scales for CWT decomposition\n",
    "\n",
    "# Create an empty list to store the CWT coefficients\n",
    "cwt_coefficients = []\n",
    "\n",
    "# Apply CWT to each sample in your data\n",
    "for sample in data2:\n",
    "    scales = pywt.central_frequency(wavelet, precision=8) * np.log2(num_scales)\n",
    "    cwt_matrix, frequencies = pywt.cwt(sample, scales, wavelet)\n",
    "    print(frequencies)\n",
    "    # Take the absolute value of the coefficients and normalize them\n",
    "    cwt_matrix = np.abs(cwt_matrix)\n",
    "    cwt_matrix /= np.max(cwt_matrix)\n",
    "\n",
    "    # Resize the coefficients to a fixed size (e.g., 32x32)\n",
    "    resized_cwt = cv2.resize(cwt_matrix, (32, 32))\n",
    "\n",
    "    # Append the resized coefficients to the list\n",
    "    cwt_coefficients.append(resized_cwt)\n",
    "\n",
    "# Convert the list to a numpy array\n",
    "cwt_coefficients = np.array(cwt_coefficients)\n",
    "\n",
    "# Reshape the array to match the input shape of the CNN\n",
    "cwt_coefficients = cwt_coefficients.reshape(-1, 32, 32, 1)\n",
    "\n",
    "# Now you can use the cwt_coefficients as input to your CNN model\n",
    "# ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8006d65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwt_coefficients.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298b7330",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2541a17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7d06ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda1e621",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937f947f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addea485",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ce7c64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd75feec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pywt\n",
    "\n",
    "# Load your dataset into a DataFrame\n",
    "df = pd.read_csv('first_try/004a-open-0.csv', sep='\\s+')\n",
    "\n",
    "electrode_columns = df.columns[2:]  \n",
    "\n",
    "n_samples = df.shape[0]\n",
    "n_channels = len(electrode_columns)\n",
    "\n",
    "# Define the wavelet parameters\n",
    "waveletname = 'morl'\n",
    "scales = range(1, 128)  # Adjust the range of scales according to your needs\n",
    "\n",
    "# Create an empty array to store the wavelet coefficients\n",
    "data_cwt = np.ndarray(shape=(n_samples, 127, 127, n_channels))\n",
    "\n",
    "# Process each sample in the dataset\n",
    "for i in range(n_samples):\n",
    "    if i % 100 == 0:\n",
    "        print(f\"Processing sample {i}\")\n",
    "    for j, column in enumerate(electrode_columns):\n",
    "        signal = df[column].iloc[i]\n",
    "        coeff, freq = pywt.cwt(signal, scales, waveletname, 1)\n",
    "        coeff_ = coeff[:, :127]  # Resize the coefficients to (127, 127)\n",
    "        data_cwt[i, :, :, j] = coeff_\n",
    "\n",
    "# Prepare the labels (adjust this part according to your dataset)\n",
    "labels = df['label'].tolist()\n",
    "\n",
    "# Split the data into train and test sets (adjust the splitting logic according to your needs)\n",
    "train_size = int(0.8 * n_samples)\n",
    "x_train = data_cwt[:train_size]\n",
    "y_train = labels[:train_size]\n",
    "x_test = data_cwt[train_size:]\n",
    "y_test = labels[train_size:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830dfaee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0916622e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.iloc[0, 0+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3886d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5955bc08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2065fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2401f198",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3cb103bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pywt\n",
    "import glob\n",
    "\n",
    "# Create an empty list to store the truncated data\n",
    "truncated_data = []\n",
    "\n",
    "# Specify the folder path where the files are located\n",
    "folder_path = \"first_try/\"\n",
    "\n",
    "# Get a list of all files in the folder\n",
    "file_list = glob.glob(folder_path + \"/*.csv\")\n",
    "\n",
    "# Loop through each file\n",
    "for file in file_list:\n",
    "    # Read the file into a DataFrame\n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    # Truncate the DataFrame to 200 rows\n",
    "    truncated_df = df[:200]\n",
    "    \n",
    "    # Add the truncated DataFrame to the list\n",
    "    truncated_data.append(truncated_df)\n",
    "\n",
    "# Concatenate all DataFrames in the list into a single DataFrame\n",
    "combined_df = pd.concat(truncated_data, ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "07384063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1643731093570</th>\n",
       "      <th>164</th>\n",
       "      <th>149</th>\n",
       "      <th>122</th>\n",
       "      <th>196</th>\n",
       "      <th>134</th>\n",
       "      <th>104</th>\n",
       "      <th>98</th>\n",
       "      <th>42</th>\n",
       "      <th>1643731153238</th>\n",
       "      <th>...</th>\n",
       "      <th>53</th>\n",
       "      <th>1643730485373</th>\n",
       "      <th>80</th>\n",
       "      <th>233</th>\n",
       "      <th>110</th>\n",
       "      <th>70</th>\n",
       "      <th>1643730582564</th>\n",
       "      <th>106</th>\n",
       "      <th>195</th>\n",
       "      <th>68.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.643731e+12</td>\n",
       "      <td>173.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.643731e+12</td>\n",
       "      <td>148.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.643731e+12</td>\n",
       "      <td>146.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.643731e+12</td>\n",
       "      <td>147.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.643731e+12</td>\n",
       "      <td>118.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.643731e+12</td>\n",
       "      <td>93.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.643731e+12</td>\n",
       "      <td>101.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.643731e+12</td>\n",
       "      <td>106.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>84.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.643731e+12</td>\n",
       "      <td>121.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.643731e+12</td>\n",
       "      <td>111.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>102.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4800 rows Ã— 157 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     1643731093570    164    149    122    196    134    104     98    42  \\\n",
       "0     1.643731e+12  173.0  154.0  121.0  214.0  141.0  134.0  108.0  48.0   \n",
       "1     1.643731e+12  148.0  136.0  123.0  228.0  131.0  135.0  113.0  51.0   \n",
       "2     1.643731e+12  146.0  148.0  118.0  202.0  109.0  136.0  112.0  49.0   \n",
       "3     1.643731e+12  147.0  146.0  119.0  190.0   96.0  142.0  111.0  45.0   \n",
       "4     1.643731e+12  118.0  144.0  117.0  199.0   96.0  150.0  114.0  47.0   \n",
       "..             ...    ...    ...    ...    ...    ...    ...    ...   ...   \n",
       "195            NaN    NaN    NaN    NaN    NaN    NaN    NaN   63.0   NaN   \n",
       "196            NaN    NaN    NaN    NaN    NaN    NaN    NaN   67.0   NaN   \n",
       "197            NaN    NaN    NaN    NaN    NaN    NaN    NaN   67.0   NaN   \n",
       "198            NaN    NaN    NaN    NaN    NaN    NaN    NaN   86.0   NaN   \n",
       "199            NaN    NaN    NaN    NaN    NaN    NaN    NaN   85.0   NaN   \n",
       "\n",
       "     1643731153238  ...  53  1643730485373  80  233  110  70  1643730582564  \\\n",
       "0              NaN  ... NaN            NaN NaN  NaN  NaN NaN            NaN   \n",
       "1              NaN  ... NaN            NaN NaN  NaN  NaN NaN            NaN   \n",
       "2              NaN  ... NaN            NaN NaN  NaN  NaN NaN            NaN   \n",
       "3              NaN  ... NaN            NaN NaN  NaN  NaN NaN            NaN   \n",
       "4              NaN  ... NaN            NaN NaN  NaN  NaN NaN            NaN   \n",
       "..             ...  ...  ..            ...  ..  ...  ...  ..            ...   \n",
       "195            NaN  ... NaN            NaN NaN  NaN  NaN NaN   1.643731e+12   \n",
       "196            NaN  ... NaN            NaN NaN  NaN  NaN NaN   1.643731e+12   \n",
       "197            NaN  ... NaN            NaN NaN  NaN  NaN NaN   1.643731e+12   \n",
       "198            NaN  ... NaN            NaN NaN  NaN  NaN NaN   1.643731e+12   \n",
       "199            NaN  ... NaN            NaN NaN  NaN  NaN NaN   1.643731e+12   \n",
       "\n",
       "       106    195   68.1  \n",
       "0      NaN    NaN    NaN  \n",
       "1      NaN    NaN    NaN  \n",
       "2      NaN    NaN    NaN  \n",
       "3      NaN    NaN    NaN  \n",
       "4      NaN    NaN    NaN  \n",
       "..     ...    ...    ...  \n",
       "195   93.0  202.0   77.0  \n",
       "196  101.0  207.0   81.0  \n",
       "197  106.0  208.0   84.0  \n",
       "198  121.0  228.0   98.0  \n",
       "199  111.0  207.0  102.0  \n",
       "\n",
       "[4800 rows x 157 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "867c0a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/pandas/core/internals/construction.py:576: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  values = np.array([convert(v) for v in values])\n"
     ]
    }
   ],
   "source": [
    "transformed_data = []\n",
    "\n",
    "scales = np.arange(1, 128)\n",
    "\n",
    "\n",
    "for file in file_list:\n",
    "    df = pd.read_csv(file)  # Assuming the data file is in CSV format\n",
    "    \n",
    "    # Apply continuous wavelet transform to each electrode column\n",
    "    for col in df.columns[1:]:  # Assuming electrode columns start from index 1\n",
    "        signal = df[col].values  # Get the values of the electrode column\n",
    "        coeff, freq = pywt.cwt(signal, scales, waveletname, 1)\n",
    "        #print(len(coeff))# Apply continuous wavelet transform\n",
    "        transformed_data.append(coeff.T)  # Append the transformed data to the list\n",
    "\n",
    "\n",
    "\n",
    "transformed_data\n",
    "#transformed_data = np.array(transformed_data, dtype=object)\n",
    "\n",
    "df = pd.DataFrame(transformed_data)\n",
    "\n",
    "#transformed_data = transformed_data.reshape(len(file_list), 200, 8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d132e2f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "966bdc9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "27b994cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(transformed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907f8ffd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d14274f1",
   "metadata": {},
   "source": [
    "## END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea44ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "0 - close\n",
    "1 - grasp\n",
    "2 - lateral\n",
    "3 - neutral\n",
    "4 - open \n",
    "5 - tripod\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7e55de",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc334d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "skewness = combined_df.skew(axis = 0, skipna = True)\n",
    "skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f230425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data is slightly skewed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc924872",
   "metadata": {},
   "source": [
    "## Splitting data according to Patient IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbfa2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients = combined_df['P_ID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dfdba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gf = combined_df.groupby('P_ID')\n",
    "\n",
    "gf.first('P_ID')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bdfbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataframe for each P_ID\n",
    "d = {}\n",
    "for p in patients:\n",
    "    d[p] = pd.DataFrame()\n",
    "\n",
    "len(patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97455150",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p, new_df in d.items():\n",
    "    d[p] = gf.get_group(p)\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad203f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "d[\"004\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3fc568",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed03585",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a56fb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
