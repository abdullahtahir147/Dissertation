{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9bcfc1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conda install -c conda-forge opencv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f487a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.0.3-cp39-cp39-macosx_10_9_x86_64.whl (11.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /opt/homebrew/anaconda3/envs/Tensor_test/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2023.3-py2.py3-none-any.whl (502 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m502.3/502.3 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tzdata>=2022.1 (from pandas)\n",
      "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.8/341.8 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting numpy>=1.20.3 (from pandas)\n",
      "  Downloading numpy-1.25.0-cp39-cp39-macosx_10_9_x86_64.whl (20.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.1/20.1 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /opt/homebrew/anaconda3/envs/Tensor_test/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Installing collected packages: pytz, tzdata, numpy, pandas\n",
      "Successfully installed numpy-1.25.0 pandas-2.0.3 pytz-2023.3 tzdata-2023.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a45b7d5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Visualizing data\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m \n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpywt\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "# Analyzing, cleaning, exploring data\n",
    "import pandas as pd \n",
    "from pandas import DataFrame\n",
    "import re\n",
    "import glob\n",
    "\n",
    "\n",
    "# Performing math operations on arrays and other structures.\n",
    "import numpy as np\n",
    "\n",
    "# Visualizing data\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import pywt\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73d48e8",
   "metadata": {},
   "source": [
    "## Importing data and extracting to a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f68412",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_list2 = []\n",
    "\n",
    "columns = ['Timestamp', 'El1', 'El2', 'El3','El4', 'El5', 'El6','El7', 'El8']\n",
    "\n",
    "\n",
    "# Specify the folder path where the CSV files are located\n",
    "folder_path = \"first_try/\"\n",
    "\n",
    "# Get a list of all CSV files in the folder\n",
    "file_list = glob.glob(folder_path + \"*.csv\")\n",
    "\n",
    "# Create an empty list to store the data from each CSV file\n",
    "dataframes = []\n",
    "total_num_rows = 0  # Variable to store the total number of rows\n",
    "extracted_strings = []\n",
    "\n",
    "\n",
    "# Loop through each CSV file, read it into a DataFrame, and append it to the list\n",
    "for file in file_list:\n",
    "    df = pd.read_csv(file, names=columns)\n",
    "    num_rows = df.shape[0]\n",
    "    \n",
    "    file_name = file.split(\"/\")[-1]  # Extract the file name from the file path\n",
    "    extracted_string = re.search(r'-(.*?)-', file_name).group(1)  # Extract the desired string using regex\n",
    "        \n",
    "    extracted_strings.extend([extracted_string] * num_rows)\n",
    "    \n",
    "    \n",
    "    extracted_numbers = re.findall(r'\\d+', file)[0]\n",
    "\n",
    "    \n",
    "    new_list = [extracted_numbers] * num_rows\n",
    "    new_list2.append(new_list)\n",
    "    dataframes.append(df)\n",
    "    \n",
    "    total_num_rows += num_rows\n",
    "\n",
    "\n",
    "# Concatenate all DataFrames in the list into a single DataFrame\n",
    "data = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "new_list2 = [item for sublist in new_list2 for item in sublist]  # Flatten the nested list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a725bb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3fbbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cb7316",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676ee5d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32994c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "data['encoded_column'] = le.fit_transform(data['Gesture'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec73a1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78b2045",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11bbfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Gesture.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acc6083",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Gesture.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f8c8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.encoded_column.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e39e604",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28e9125",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c732ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = data.hist(figsize=(16, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0916622e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.iloc[0, 0+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3886d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2401f198",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2630460",
   "metadata": {},
   "outputs": [],
   "source": [
    "truncated_data = []\n",
    "new_list2 = []\n",
    "dataframes = []\n",
    "total_num_rows = 0  # Variable to store the total number of rows\n",
    "extracted_strings = []\n",
    "\n",
    "gesture_list = []\n",
    "\n",
    "# Specify the folder path where the CSV files are located\n",
    "folder_path = \"Test/\"\n",
    "\n",
    "columns = ['Timestamp', 'El1', 'El2', 'El3','El4', 'El5', 'El6','El7', 'El8']\n",
    "\n",
    "\n",
    "# Get a list of all CSV files in the folder\n",
    "file_list = glob.glob(folder_path + \"*.csv\")\n",
    "\n",
    "for file in file_list:\n",
    "    df = pd.read_csv(file, names=columns)\n",
    "    \n",
    "    # Truncate the DataFrame to 127 rows\n",
    "    truncated_df = df[:100]\n",
    "    \n",
    "    # Add the truncated DataFrame to the list\n",
    "    truncated_data.append(truncated_df)\n",
    "    num_rows = 200\n",
    "    \n",
    "    file_name = file.split(\"/\")[-1]  # Extract the file name from the file path\n",
    "    gesture = re.search(r'-(.*?)-', file_name).group(1)  # Extract the desired string using regex\n",
    "        \n",
    "    gesture_list.extend([gesture])\n",
    "    \n",
    "    extracted_strings.extend([gesture] * num_rows)\n",
    "    \n",
    "    \n",
    "    extracted_numbers = re.findall(r'\\d+', file)[0]\n",
    "\n",
    "    \n",
    "    new_list = [extracted_numbers] * num_rows\n",
    "    new_list2.append(new_list)\n",
    "    dataframes.append(df)\n",
    "    \n",
    "    total_num_rows += num_rows\n",
    "    filtered_dataframes = [truncated_data for truncated_data in dataframes if len(truncated_data) <= 200]\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "combined_df = pd.concat(truncated_data, ignore_index=False)\n",
    "new_list2 = [item for sublist in new_list2 for item in sublist]  # Flatten the nested list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "035e3e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(filtered_dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab3c90a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1eba7706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['open', 'open']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gesture_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50a13b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combined_df[\"P_ID\"] = new_list2\n",
    "#combined_df[\"Gesture\"] = extracted_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1abc27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#target = combined_df[\"Gesture\"].copy()\n",
    "#combined_df =combined_df.drop('Gesture', axis= 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2db4b2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7b0a6d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>El1</th>\n",
       "      <th>El2</th>\n",
       "      <th>El3</th>\n",
       "      <th>El4</th>\n",
       "      <th>El5</th>\n",
       "      <th>El6</th>\n",
       "      <th>El7</th>\n",
       "      <th>El8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1643730362244</td>\n",
       "      <td>172</td>\n",
       "      <td>168</td>\n",
       "      <td>147</td>\n",
       "      <td>394</td>\n",
       "      <td>293</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1643730362388</td>\n",
       "      <td>185</td>\n",
       "      <td>188</td>\n",
       "      <td>155</td>\n",
       "      <td>378</td>\n",
       "      <td>279</td>\n",
       "      <td>117</td>\n",
       "      <td>105</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1643730362525</td>\n",
       "      <td>196</td>\n",
       "      <td>190</td>\n",
       "      <td>162</td>\n",
       "      <td>387</td>\n",
       "      <td>286</td>\n",
       "      <td>123</td>\n",
       "      <td>109</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1643730362652</td>\n",
       "      <td>212</td>\n",
       "      <td>182</td>\n",
       "      <td>177</td>\n",
       "      <td>390</td>\n",
       "      <td>273</td>\n",
       "      <td>122</td>\n",
       "      <td>108</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1643730362779</td>\n",
       "      <td>183</td>\n",
       "      <td>178</td>\n",
       "      <td>189</td>\n",
       "      <td>413</td>\n",
       "      <td>248</td>\n",
       "      <td>128</td>\n",
       "      <td>104</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1643730308063</td>\n",
       "      <td>88</td>\n",
       "      <td>135</td>\n",
       "      <td>98</td>\n",
       "      <td>235</td>\n",
       "      <td>122</td>\n",
       "      <td>125</td>\n",
       "      <td>88</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1643730308068</td>\n",
       "      <td>90</td>\n",
       "      <td>128</td>\n",
       "      <td>97</td>\n",
       "      <td>244</td>\n",
       "      <td>111</td>\n",
       "      <td>129</td>\n",
       "      <td>94</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1643730308074</td>\n",
       "      <td>78</td>\n",
       "      <td>113</td>\n",
       "      <td>96</td>\n",
       "      <td>232</td>\n",
       "      <td>119</td>\n",
       "      <td>134</td>\n",
       "      <td>102</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1643730308079</td>\n",
       "      <td>84</td>\n",
       "      <td>131</td>\n",
       "      <td>94</td>\n",
       "      <td>222</td>\n",
       "      <td>121</td>\n",
       "      <td>135</td>\n",
       "      <td>103</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1643730308085</td>\n",
       "      <td>80</td>\n",
       "      <td>124</td>\n",
       "      <td>92</td>\n",
       "      <td>238</td>\n",
       "      <td>115</td>\n",
       "      <td>143</td>\n",
       "      <td>104</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Timestamp  El1  El2  El3  El4  El5  El6  El7  El8\n",
       "0   1643730362244  172  168  147  394  293  101  101   57\n",
       "1   1643730362388  185  188  155  378  279  117  105   63\n",
       "2   1643730362525  196  190  162  387  286  123  109   73\n",
       "3   1643730362652  212  182  177  390  273  122  108   75\n",
       "4   1643730362779  183  178  189  413  248  128  104   74\n",
       "..            ...  ...  ...  ...  ...  ...  ...  ...  ...\n",
       "95  1643730308063   88  135   98  235  122  125   88   37\n",
       "96  1643730308068   90  128   97  244  111  129   94   35\n",
       "97  1643730308074   78  113   96  232  119  134  102   38\n",
       "98  1643730308079   84  131   94  222  121  135  103   40\n",
       "99  1643730308085   80  124   92  238  115  143  104   40\n",
       "\n",
       "[200 rows x 9 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ceba0735",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = combined_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18f9e35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3597c70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the parameters\n",
    "scales = np.arange(1, 101)\n",
    "waveletname = \"morl\"\n",
    "num_rows = 100\n",
    "num_columns = 8\n",
    "\n",
    "\n",
    "# Extract the electrode readings columns\n",
    "data = df.iloc[:, 1:].values  # Exclude the timestamp column\n",
    "\n",
    "# Reshape the data into 3D array (number of samples, number of rows, number of columns)\n",
    "data = data.reshape(-1, num_rows, num_columns)\n",
    "\n",
    "# Apply continuous wavelet transform to each sample\n",
    "transformed_data = []\n",
    "\n",
    "\n",
    "for sample in data:\n",
    "    transformed_sample = []\n",
    "    for channel in sample.T:  # Transpose to loop over columns (channels)\n",
    "        coeff, _ = pywt.cwt(channel, scales, waveletname, 1)\n",
    "        transformed_sample.append(coeff)\n",
    "    transformed_data.append(np.array(transformed_sample))\n",
    "\n",
    "# Convert the transformed data into a numpy array\n",
    "transformed_data = np.array(transformed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c83f0f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea3d02f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_data = transformed_data.transpose((0, 3, 2, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "444b6328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 100, 100, 8)\n"
     ]
    }
   ],
   "source": [
    "# 24 files - signals\n",
    "# 100 rows \n",
    "# 100 coefficients for each row\n",
    "# 8 channels - columns\n",
    "print(reshaped_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97491bcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7757124",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(reshaped_data, gesture_list, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9bc37256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9118d748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.12.0-cp39-cp39-macosx_10_15_x86_64.whl (230.1 MB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Using cached absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting flatbuffers>=2.0 (from tensorflow)\n",
      "  Using cached flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow)\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting h5py>=2.9.0 (from tensorflow)\n",
      "  Downloading h5py-3.9.0-cp39-cp39-macosx_10_9_x86_64.whl (3.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting jax>=0.3.15 (from tensorflow)\n",
      "  Using cached jax-0.4.13-py3-none-any.whl\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Using cached libclang-16.0.0-py2.py3-none-macosx_10_9_x86_64.whl (26.7 MB)\n",
      "Collecting numpy<1.24,>=1.22 (from tensorflow)\n",
      "  Downloading numpy-1.23.5-cp39-cp39-macosx_10_9_x86_64.whl (18.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied: packaging in /opt/homebrew/anaconda3/envs/Tensor_test/lib/python3.9/site-packages (from tensorflow) (23.0)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow)\n",
      "  Downloading protobuf-4.23.3-cp37-abi3-macosx_10_9_universal2.whl (400 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.3/400.3 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /opt/homebrew/anaconda3/envs/Tensor_test/lib/python3.9/site-packages (from tensorflow) (67.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/homebrew/anaconda3/envs/Tensor_test/lib/python3.9/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/homebrew/anaconda3/envs/Tensor_test/lib/python3.9/site-packages (from tensorflow) (4.6.3)\n",
      "Collecting wrapt<1.15,>=1.11.0 (from tensorflow)\n",
      "  Using cached wrapt-1.14.1-cp39-cp39-macosx_10_9_x86_64.whl (35 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.56.0-cp39-cp39-macosx_10_10_universal2.whl (8.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard<2.13,>=2.12 (from tensorflow)\n",
      "  Downloading tensorboard-2.12.3-py3-none-any.whl (5.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow-estimator<2.13,>=2.12.0 (from tensorflow)\n",
      "  Using cached tensorflow_estimator-2.12.0-py2.py3-none-any.whl (440 kB)\n",
      "Collecting keras<2.13,>=2.12.0 (from tensorflow)\n",
      "  Using cached keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.32.0-cp39-cp39-macosx_10_14_x86_64.whl (1.7 MB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/homebrew/anaconda3/envs/Tensor_test/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
      "Collecting ml-dtypes>=0.1.0 (from jax>=0.3.15->tensorflow)\n",
      "  Using cached ml_dtypes-0.2.0-cp39-cp39-macosx_10_9_universal2.whl (1.2 MB)\n",
      "Collecting scipy>=1.7 (from jax>=0.3.15->tensorflow)\n",
      "  Downloading scipy-1.11.1-cp39-cp39-macosx_10_9_x86_64.whl (37.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.2/37.2 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata>=4.6 in /opt/homebrew/anaconda3/envs/Tensor_test/lib/python3.9/site-packages (from jax>=0.3.15->tensorflow) (6.0.0)\n",
      "Collecting google-auth<3,>=1.6.3 (from tensorboard<2.13,>=2.12->tensorflow)\n",
      "  Downloading google_auth-2.21.0-py2.py3-none-any.whl (182 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.1/182.1 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.13,>=2.12->tensorflow)\n",
      "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.13,>=2.12->tensorflow)\n",
      "  Downloading Markdown-3.4.3-py3-none-any.whl (93 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.9/93.9 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting requests<3,>=2.21.0 (from tensorboard<2.13,>=2.12->tensorflow)\n",
      "  Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.13,>=2.12->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.1-py3-none-macosx_10_9_x86_64.whl (4.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting werkzeug>=1.0.1 (from tensorboard<2.13,>=2.12->tensorflow)\n",
      "  Downloading Werkzeug-2.3.6-py3-none-any.whl (242 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cachetools<6.0,>=2.0.0 (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow)\n",
      "  Downloading cachetools-5.3.1-py3-none-any.whl (9.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow)\n",
      "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.3/181.3 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting rsa<5,>=3.1.4 (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow)\n",
      "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting urllib3<2.0 (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow)\n",
      "  Downloading urllib3-1.26.16-py2.py3-none-any.whl (143 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.1/143.1 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow)\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/homebrew/anaconda3/envs/Tensor_test/lib/python3.9/site-packages (from importlib-metadata>=4.6->jax>=0.3.15->tensorflow) (3.11.0)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow)\n",
      "  Downloading charset_normalizer-3.1.0-cp39-cp39-macosx_10_9_x86_64.whl (124 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.7/124.7 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: idna<4,>=2.5 in /opt/homebrew/anaconda3/envs/Tensor_test/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.4)\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow)\n",
      "  Downloading certifi-2023.5.7-py3-none-any.whl (156 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.0/157.0 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/homebrew/anaconda3/envs/Tensor_test/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.1)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow)\n",
      "  Downloading pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.9/83.9 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25hCollecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow)\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Installing collected packages: libclang, flatbuffers, wrapt, werkzeug, urllib3, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, pyasn1, protobuf, oauthlib, numpy, keras, grpcio, google-pasta, gast, charset-normalizer, certifi, cachetools, astunparse, absl-py, scipy, rsa, requests, pyasn1-modules, opt-einsum, ml-dtypes, markdown, h5py, requests-oauthlib, jax, google-auth, google-auth-oauthlib, tensorboard, tensorflow\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.25.0\n",
      "    Uninstalling numpy-1.25.0:\n",
      "      Successfully uninstalled numpy-1.25.0\n",
      "Successfully installed absl-py-1.4.0 astunparse-1.6.3 cachetools-5.3.1 certifi-2023.5.7 charset-normalizer-3.1.0 flatbuffers-23.5.26 gast-0.4.0 google-auth-2.21.0 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 grpcio-1.56.0 h5py-3.9.0 jax-0.4.13 keras-2.12.0 libclang-16.0.0 markdown-3.4.3 ml-dtypes-0.2.0 numpy-1.23.5 oauthlib-3.2.2 opt-einsum-3.3.0 protobuf-4.23.3 pyasn1-0.5.0 pyasn1-modules-0.3.0 requests-2.31.0 requests-oauthlib-1.3.1 rsa-4.9 scipy-1.11.1 tensorboard-2.12.3 tensorboard-data-server-0.7.1 tensorflow-2.12.0 tensorflow-estimator-2.12.0 tensorflow-io-gcs-filesystem-0.32.0 termcolor-2.3.0 urllib3-1.26.16 werkzeug-2.3.6 wrapt-1.14.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69759019",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc027247",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822ee474",
   "metadata": {},
   "source": [
    "## CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cb415a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# Build a basic CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(16, (3, 3), activation=\"relu\", input_shape=(num_rows, num_columns, len(scales))))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(32, (3, 3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the model\n",
    "#model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "#model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b84d40a",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (365468493.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    jupyter notebook --generate-config\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "jupyter notebook --generate-config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc63793",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
